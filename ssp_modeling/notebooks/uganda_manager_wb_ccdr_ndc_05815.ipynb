{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a29eb0a-00ee-494d-9b3d-25da412bf1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-15 16:08:11,328 - INFO - Notebook started successfully.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import datetime as dt\n",
    "import importlib # needed so that we can reload packages\n",
    "import matplotlib.pyplot as plt\n",
    "import os, os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import sys\n",
    "import time\n",
    "from typing import Union\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "from utils.logger_utils import setup_clean_logger, mute_external_loggers\n",
    "\n",
    "# Set up a clean logger for your notebook\n",
    "logger = setup_clean_logger(\"notebook\", logging.INFO)\n",
    "logger.info(\"Notebook started successfully.\")\n",
    "\n",
    "# Mute logs from sisepuede to avoid duplication\n",
    "mute_external_loggers([\"sisepuede\"])\n",
    "\n",
    "\n",
    "##  IMPORT SISEPUEDE EXAMPLES AND TRANSFORMERS\n",
    "\n",
    "from sisepuede.manager.sisepuede_examples import SISEPUEDEExamples\n",
    "from sisepuede.manager.sisepuede_file_structure import SISEPUEDEFileStructure\n",
    "import sisepuede.core.support_classes as sc\n",
    "import sisepuede.transformers as trf\n",
    "import sisepuede.utilities._plotting as spu\n",
    "import sisepuede.utilities._toolbox as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e361ab62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected IPython. Loading juliacall extension. See https://juliapy.github.io/PythonCall.jl/stable/compat/#IPython\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precompiling NemoMod...\n",
      "Info Given NemoMod was explicitly requested, output will be shown live \u001b[0K\n",
      "\u001b[0KWARNING: Method definition parse_line(String) in module ConfParser at /Users/fabianfuentes/.julia/packages/ConfParser/b2fge/src/ConfParser.jl:95 overwritten in module NemoMod at /Users/fabianfuentes/.julia/packages/NemoMod/p49Bn/src/other_functions.jl:35.\n",
      "\u001b[0KERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\n",
      "   1084.8 ms  ? NemoMod\n",
      "[ Info: Precompiling NemoMod [a3c327a0-d2f0-11e8-37fd-d12fd35c3c72] \n",
      "WARNING: Method definition parse_line(String) in module ConfParser at /Users/fabianfuentes/.julia/packages/ConfParser/b2fge/src/ConfParser.jl:95 overwritten in module NemoMod at /Users/fabianfuentes/.julia/packages/NemoMod/p49Bn/src/other_functions.jl:35.\n",
      "ERROR: Method overwriting is not permitted during Module precompilation. Use `__precompile__(false)` to opt-out of precompilation.\n",
      "┌ Info: Skipping precompilation due to precompilable error. Importing NemoMod [a3c327a0-d2f0-11e8-37fd-d12fd35c3c72].\n",
      "└   exception = Error when precompiling module, potentially caused by a __precompile__(false) declaration in the module.\n"
     ]
    }
   ],
   "source": [
    "# Save original path\n",
    "original_sys_path = list(sys.path)\n",
    "\n",
    "# Add the custom path\n",
    "custom_path = os.path.abspath(\"../../data_processing/utils\")\n",
    "sys.path.append(custom_path)\n",
    "\n",
    "# Import your module\n",
    "import common_data_needs as cdn\n",
    "\n",
    "# Revert to original sys.path\n",
    "sys.path = original_sys_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49d7c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0483f2b",
   "metadata": {},
   "source": [
    "### Initial Set up\n",
    "\n",
    "Make sure to edit the config yaml under ssp_modeling/config_files/config.yaml\n",
    "\n",
    "You can also create a new config yaml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aebcd791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dir paths\n",
    "\n",
    "CURR_DIR_PATH = pathlib.Path(os.getcwd())\n",
    "SSP_MODELING_DIR_PATH = CURR_DIR_PATH.parent\n",
    "PROJECT_DIR_PATH = SSP_MODELING_DIR_PATH.parent\n",
    "DATA_DIR_PATH = SSP_MODELING_DIR_PATH.joinpath(\"input_data\")\n",
    "RUN_OUTPUT_DIR_PATH = SSP_MODELING_DIR_PATH.joinpath(\"ssp_run_output\")\n",
    "SCENARIO_MAPPING_DIR_PATH = SSP_MODELING_DIR_PATH.joinpath(\"scenario_mapping\")\n",
    "CONFIG_DIR_PATH = SSP_MODELING_DIR_PATH.joinpath(\"config_files\")\n",
    "TRANSFORMATIONS_DIR_PATH = SSP_MODELING_DIR_PATH.joinpath(\"transformations\")\n",
    "MISC_DIR_PATH = SSP_MODELING_DIR_PATH.joinpath(\"misc\")\n",
    "STRATEGIES_DEFINITIONS_FILE_PATH = TRANSFORMATIONS_DIR_PATH.joinpath(\"strategy_definitions.csv\")\n",
    "STRATEGY_MAPPING_FILE_PATH = MISC_DIR_PATH.joinpath(\"strategy_mapping.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac941c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssp_transformations_handler.GeneralUtils import GeneralUtils\n",
    "from ssp_transformations_handler.TransformationUtils import TransformationYamlProcessor, StrategyCSVHandler\n",
    "\n",
    "# Initialize general utilities\n",
    "g_utils = GeneralUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53908ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-15 16:08:29,247 - INFO - Country name: uganda\n",
      "2025-08-15 16:08:29,247 - INFO - SSP input file name: None\n",
      "2025-08-15 16:08:29,247 - INFO - SSP transformation CW: ssp_uganda_transformation_cw_NDC_2.0.xlsx\n",
      "2025-08-15 16:08:29,247 - INFO - Energy model flag: True\n",
      "2025-08-15 16:08:29,248 - INFO - Set lndu reallocation factor to zero flag: True\n"
     ]
    }
   ],
   "source": [
    "# Load config file, double check your parameters are correct\n",
    "\n",
    "YAML_FILE_PATH = os.path.join(CONFIG_DIR_PATH, \"config_ccdr_ndc_2.0.yaml\")\n",
    "config_params = g_utils.read_yaml(YAML_FILE_PATH)\n",
    "\n",
    "country_name = config_params['country_name']\n",
    "ssp_input_file_name = config_params['ssp_input_file_name']\n",
    "ssp_transformation_cw = config_params['ssp_transformation_cw']\n",
    "energy_model_flag = config_params['energy_model_flag']\n",
    "set_lndu_reallocation_factor_to_zero_flag = config_params['set_lndu_reallocation_factor_to_zero']\n",
    "\n",
    "# Print config parameters\n",
    "logger.info(f\"Country name: {country_name}\")\n",
    "logger.info(f\"SSP input file name: {ssp_input_file_name}\")\n",
    "logger.info(f\"SSP transformation CW: {ssp_transformation_cw}\")\n",
    "logger.info(f\"Energy model flag: {energy_model_flag}\")\n",
    "logger.info(f\"Set lndu reallocation factor to zero flag: {set_lndu_reallocation_factor_to_zero_flag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c6c558-ba2c-482b-8743-7c46bfb64924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up SSP objects\n",
    "\n",
    "# INPUT_FILE_PATH = DATA_DIR_PATH.joinpath(ssp_input_file_name)\n",
    "\n",
    "# file_struct = SISEPUEDEFileStructure()\n",
    "\n",
    "# matt = file_struct.model_attributes\n",
    "# regions = sc.Regions(matt)\n",
    "# time_periods = sc.TimePeriods(matt)\n",
    "\n",
    "dict_ssp = cdn._setup_sisepuede_elements()\n",
    "\n",
    "matt = dict_ssp.get(\"model_attributes\", )\n",
    "models = dict_ssp.get(\"models\", )\n",
    "regions = dict_ssp.get(\"regions\", )\n",
    "time_periods = dict_ssp.get(\"time_periods\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f64c6a",
   "metadata": {},
   "source": [
    "### Making sure our input file has the correct format and correct columns\n",
    "We use an example df with the complete fields and correct format to make sure our file is in the right shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cb485b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/fabianfuentes/git/ssp_uganda_data/data_processing/output_data')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdn._PATH_OUTPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e722a2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot proceed: fields 'ef_soil_c_cultivated_organic_temperate_crop_grass_tonne_per_ha', 'ef_soil_c_cultivated_organic_tropical_crop_grass_tonne_per_ha' not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_inputs_raw = \u001b[43mcdn\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_build_from_outputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtime_periods\u001b[49m\u001b[43m.\u001b[49m\u001b[43mall_years\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtime_periods\u001b[49m\u001b[43m.\u001b[49m\u001b[43mall_years\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfns_exclude\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrac_lndu_initial.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmerge_type\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mouter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_info\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstop_on_error\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m df_inputs_raw.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ssp_uganda_data/data_processing/utils/common_data_needs.py:173\u001b[39m, in \u001b[36m_build_from_outputs\u001b[39m\u001b[34m(years_required, extension_read, fns_exclude, force_complete_build, merge_type, path_csvs, print_info, stop_on_error, **kwargs)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force_complete_build:\n\u001b[32m    172\u001b[39m     fields_missing = sf.format_print_list(fields_missing, )\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot proceed: fields \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfields_missing\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    175\u001b[39m \u001b[38;5;66;03m# add in values from examples\u001b[39;00m\n\u001b[32m    176\u001b[39m df_base = (\n\u001b[32m    177\u001b[39m     pd.merge(\n\u001b[32m    178\u001b[39m         df_base,\n\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m     .reset_index(drop = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    188\u001b[39m )\n",
      "\u001b[31mRuntimeError\u001b[39m: Cannot proceed: fields 'ef_soil_c_cultivated_organic_temperate_crop_grass_tonne_per_ha', 'ef_soil_c_cultivated_organic_tropical_crop_grass_tonne_per_ha' not found."
     ]
    }
   ],
   "source": [
    "df_inputs_raw = cdn._build_from_outputs(\n",
    "    (\n",
    "        min(time_periods.all_years),\n",
    "        max(time_periods.all_years)\n",
    "    ),\n",
    "    fns_exclude = [\"frac_lndu_initial.csv\"],\n",
    "    merge_type = \"outer\", \n",
    "    print_info = False,\n",
    "    stop_on_error = True, \n",
    ")\n",
    "\n",
    "df_inputs_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9934314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs_raw.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a1e26f-7946-4f4f-a3b1-ff398c9fe211",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  BUILD BASE INPUTS\n",
    "# df_inputs_raw = pd.read_csv(INPUT_FILE_PATH)\n",
    "\n",
    "# pull example data to fill in gaps\n",
    "examples = SISEPUEDEExamples()\n",
    "df_inputs_example = examples.input_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e38e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double checking that our df is in the correct shape (Empty sets should be printed to make sure everything is Ok!)\n",
    "g_utils.compare_dfs(df_inputs_example, df_inputs_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b012cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure if time_period field exist\n",
    "if 'time_period' not in df_inputs_raw.columns:\n",
    "    logger.info(\"Adding 'time_period' column to df_inputs_raw\")\n",
    "    df_inputs_raw = df_inputs_raw.rename(columns={'period':'time_period'})\n",
    "else:\n",
    "    logger.info(\"'time_period' column already exists in df_inputs_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d18008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixes differences and makes sure that our df is in the correct format.\n",
    "# Note: Edit this if you need more changes in your df\n",
    "df_inputs_raw_complete = g_utils.add_missing_cols(df_inputs_example, df_inputs_raw.copy())\n",
    "df_inputs_raw_complete = g_utils.remove_additional_cols(df_inputs_example, df_inputs_raw_complete.copy())\n",
    "df_inputs_raw_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f1d947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double checking that our df is in the correct shape (Empty sets should be printed to make sure everything is Ok!)\n",
    "g_utils.compare_dfs(df_inputs_example, df_inputs_raw_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6d5d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set region to country name\n",
    "df_inputs_raw_complete['region'] = country_name\n",
    "df_inputs_raw_complete['region'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b179e3",
   "metadata": {},
   "source": [
    "## Let's Modify the  LNDU Reallocation factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d97b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_lndu_reallocation_factor_to_zero_flag:\n",
    "    df_inputs_raw_complete['lndu_reallocation_factor'] = 0\n",
    "\n",
    "df_inputs_raw_complete['lndu_reallocation_factor'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514fbbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fields with nulls\n",
    "fields_with_nulls = df_inputs_raw_complete.columns[df_inputs_raw_complete.isnull().any()].tolist()\n",
    "fields_with_nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91491c34-78de-4bf9-bed3-3d69613bace7",
   "metadata": {},
   "source": [
    "#  Let's try building transformations using this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f21339f-7e93-4123-aa07-8a12f0316756",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = trf.transformers.Transformers(\n",
    "    {},\n",
    "    attr_time_period = cdn._ATTRIBUTE_TABLE_TIME_PERIOD,\n",
    "    df_input = df_inputs_raw_complete,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93521f1-0fa0-4f09-9b6e-def5662df3d8",
   "metadata": {},
   "source": [
    "##  Instantiate some transformations. Make sure to run this cell to create the transformations folder for the first time or if you wish to overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85aa9b2-412c-44f7-b75f-3bc486202843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set an ouput path and instantiate\n",
    "if not TRANSFORMATIONS_DIR_PATH.exists():\n",
    "    trf.instantiate_default_strategy_directory(\n",
    "        transformers,\n",
    "        TRANSFORMATIONS_DIR_PATH,\n",
    "    )\n",
    "else:\n",
    "    logger.info(f\"Directory {TRANSFORMATIONS_DIR_PATH} already exists. Skipping instantiation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14522780-2f45-4402-8889-365f1d319303",
   "metadata": {},
   "source": [
    "##  --HERE, CUSTOMIZE YOUR TRANSFORMATIONS AND STRATEGIES--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03361640",
   "metadata": {},
   "source": [
    "### Customizing transformations and strategies files using TransformationUtils.py classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new transformation files based on the excel mapping file. \n",
    "# Make sure to have the most updated format for the excel file, check the one used in this notebook for reference.\n",
    "\n",
    "if ssp_transformation_cw is None:\n",
    "    logger.warning(\"ssp_transformation_cw is not defined. Please check your config file.\")\n",
    "else:\n",
    "    logger.info(f\"Using transformation file: {ssp_transformation_cw}\")\n",
    "    cw_file_path = os.path.join(SCENARIO_MAPPING_DIR_PATH, ssp_transformation_cw)\n",
    "    logger.info(f\"Transformation file path: {cw_file_path}\")\n",
    "    excel_yaml_handler = TransformationYamlProcessor(scenario_mapping_excel_path=cw_file_path, yaml_dir_path=TRANSFORMATIONS_DIR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates transformation yaml files for each strategy in the excel file\n",
    "if ssp_transformation_cw is not None:\n",
    "    logger.info(\"Processing YAML files...\")\n",
    "    excel_yaml_handler.process_yaml_files()\n",
    "else:\n",
    "    logger.warning(\"ssp_transformation_cw is not defined. Please check your config file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transformations per strategy dictionary so we can pass it to the strategy handler\n",
    "# You can also check here if the transformations in each strategy are correct\n",
    "\n",
    "if ssp_transformation_cw is not None:\n",
    "    logger.info(\"Loading transformations per strategy dictionary...\")\n",
    "    transformation_per_strategy_dict = excel_yaml_handler.get_transformations_per_strategy_dict()\n",
    "    transformation_per_strategy_dict\n",
    "    logger.info(f\"Loaded transformations for strategies: {transformation_per_strategy_dict.keys()}\")\n",
    "else:\n",
    "    logger.warning(\"No transformation handler available. Please check your config file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb689de1",
   "metadata": {},
   "source": [
    "### Creating new strategies\n",
    "- You can create new strategies from scratch.\n",
    "- You can also update existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea277ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new strategies by updating the strategy_definitions file.\n",
    "\n",
    "if ssp_transformation_cw is not None:\n",
    "    # You can edit this to add yours, as many as you want.\n",
    "    csv_handler = StrategyCSVHandler(csv_file_path=STRATEGIES_DEFINITIONS_FILE_PATH, \n",
    "                                     yaml_dir_path=TRANSFORMATIONS_DIR_PATH, \n",
    "                                     yaml_mapping_file=STRATEGY_MAPPING_FILE_PATH, \n",
    "                                     transformation_per_strategy_dict=transformation_per_strategy_dict)\n",
    "    \n",
    "    for strategy_name in transformation_per_strategy_dict.keys():\n",
    "        yaml_file_suffix = strategy_name.split('strategy_')[-1]\n",
    "        csv_handler.add_strategy(strategy_group='PFLO', description='Custom Strategy', yaml_file_suffix=yaml_file_suffix)\n",
    "\n",
    "else:\n",
    "    logger.warning(\"No transformation handler available. Please check your config file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8763ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the strategy codes you wish to run in ssp\n",
    "strategies_to_run = [0, 6003, 6004, 6005, 6006]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f42b6f4",
   "metadata": {},
   "source": [
    "## TX:LNDU:DEC_DEFORESTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df6c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import yaml\n",
    "\n",
    "with open(os.path.join(TRANSFORMATIONS_DIR_PATH, 'transformation_lndu_dec_deforestation_strategy_NZ.yaml'), 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "\n",
    "data['parameters']['magnitude'] = 0.9999999   \n",
    "\n",
    "\n",
    "with open(os.path.join(TRANSFORMATIONS_DIR_PATH, 'transformation_lndu_dec_deforestation_strategy_NZ.yaml'), 'w') as file:\n",
    "    yaml.dump(data, file, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284fdaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(os.path.join(TRANSFORMATIONS_DIR_PATH, 'transformation_lndu_dec_deforestation_strategy_NDC.yaml'), 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "\n",
    "data['parameters']['magnitude'] = 0.996\n",
    "\n",
    "\n",
    "with open(os.path.join(TRANSFORMATIONS_DIR_PATH, 'transformation_lndu_dec_deforestation_strategy_NDC.yaml'), 'w') as file:\n",
    "    yaml.dump(data, file, sort_keys=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82755dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(os.path.join(TRANSFORMATIONS_DIR_PATH, 'transformation_lndu_dec_deforestation_strategy_NDC_2.yaml'), 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "\n",
    "data['parameters']['magnitude'] = 0.996\n",
    "\n",
    "\n",
    "with open(os.path.join(TRANSFORMATIONS_DIR_PATH, 'transformation_lndu_dec_deforestation_strategy_NDC_2.yaml'), 'w') as file:\n",
    "    yaml.dump(data, file, sort_keys=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f68f45d",
   "metadata": {},
   "source": [
    "## TX:AGRC:INC_CONSERVATION_AGRICULTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ffa3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(TRANSFORMATIONS_DIR_PATH, 'transformation_agrc_inc_conservation_agriculture_strategy_NZ.yaml'), 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "\n",
    "data['parameters']['magnitude_burned'] = 0.8\n",
    "data['parameters']['magnitude_removed'] = 0.8   \n",
    "\n",
    "\n",
    "with open(os.path.join(TRANSFORMATIONS_DIR_PATH, 'transformation_agrc_inc_conservation_agriculture_strategy_NZ.yaml'), 'w') as file:\n",
    "    yaml.dump(data, file, sort_keys=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19fcb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(TRANSFORMATIONS_DIR_PATH, 'transformation_agrc_inc_conservation_agriculture_strategy_NDC.yaml'), 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "\n",
    "data['parameters']['magnitude_burned'] = 0.6\n",
    "data['parameters']['magnitude_removed'] = 0.6   \n",
    "\n",
    "\n",
    "with open(os.path.join(TRANSFORMATIONS_DIR_PATH, 'transformation_agrc_inc_conservation_agriculture_strategy_NDC.yaml'), 'w') as file:\n",
    "    yaml.dump(data, file, sort_keys=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe998ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(TRANSFORMATIONS_DIR_PATH, 'transformation_agrc_inc_conservation_agriculture_strategy_NDC_2.yaml'), 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "\n",
    "data['parameters']['magnitude_burned'] = 0.6\n",
    "data['parameters']['magnitude_removed'] = 0.6   \n",
    "\n",
    "\n",
    "with open(os.path.join(TRANSFORMATIONS_DIR_PATH, 'transformation_agrc_inc_conservation_agriculture_strategy_NDC_2.yaml'), 'w') as file:\n",
    "    yaml.dump(data, file, sort_keys=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1763d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b7c7b74",
   "metadata": {},
   "source": [
    "### We finished adding new transformation files and strategies so lets load them back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bd1a2f-4f3e-4c78-b9a6-b00446ee44ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then, you can load this back in after modifying (play around with it)\n",
    "transformations = trf.Transformations(\n",
    "    TRANSFORMATIONS_DIR_PATH,\n",
    "    transformers = transformers,\n",
    ")\n",
    "tab = transformations.attribute_transformation.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20cd07a-feb1-4b4c-a755-43d0f639e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  build the strategies -- will export to path\n",
    "t0 = time.time()\n",
    "strategies = trf.Strategies(\n",
    "    transformations,\n",
    "    export_path = \"transformations\",\n",
    "    prebuild = True,\n",
    ")\n",
    "\n",
    "t_elapse = sf.get_time_elapsed(t0)\n",
    "logger.info(f\"Strategies defined at {strategies.transformations.dir_init} initialized in {t_elapse} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937acf95-47c5-42d2-bec4-1960ca8bb3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies.attribute_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960373ce-9c92-4998-87e1-79563b4b7800",
   "metadata": {},
   "source": [
    "##  Build our templates\n",
    "- let's use the default variable groupings for LHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46000c-f47a-4fcd-ae46-44bf7fab2e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building excel templates, make sure to include the strategies ids in the strategies attribute as well as the baseline (0)\n",
    "df_vargroups = examples(\"variable_trajectory_group_specification\")\n",
    "\n",
    "strategies.build_strategies_to_templates(\n",
    "    #df_trajgroup = df_vargroups,\n",
    "    #include_simplex_group_as_trajgroup = True,\n",
    "    strategies = strategies_to_run,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec04da7-dd23-437c-bcc2-fd63541c44f5",
   "metadata": {},
   "source": [
    "# Finally, load SISEPUEDE so that we can run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa73794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sisepuede as si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749d1cae-41a3-4344-b0ff-db9d8d41a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# timestamp_str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "ssp = si.SISEPUEDE(\n",
    "    \"calibrated\",\n",
    "    db_type = \"csv\",\n",
    "    #id_str = f\"sisepuede_run_2025-07-28T12:30:52.790396\",\n",
    "    initialize_as_dummy = not(energy_model_flag), # no connection to Julia is initialized if set to True\n",
    "    regions = [country_name],\n",
    "    strategies = strategies,\n",
    "    #try_exogenous_xl_types_in_variable_specification = True,\n",
    "    attribute_time_period = cdn._ATTRIBUTE_TABLE_TIME_PERIOD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace8ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "not(energy_model_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e24634e-19a9-457f-909f-be5696f1ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This runs the model, make sure you edit key_stretegy with the strategy ids you want to execute include baseline (0)\n",
    "dict_scens = {\n",
    "    ssp.key_design: [0],\n",
    "    ssp.key_future: [0],\n",
    "    ssp.key_strategy: strategies_to_run,\n",
    "}\n",
    "\n",
    "ssp.project_scenarios(\n",
    "    dict_scens,\n",
    "    save_inputs = True,\n",
    "    include_electricity_in_energy = energy_model_flag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f54b8-82f4-47e0-99a0-47b894039ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input and output files\n",
    "df_out = ssp.read_output(None)\n",
    "df_in = ssp.read_input(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c08848-2cd8-46bf-8ad3-3e24ec4abbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a559a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_field_stack(\n",
    "    df,\n",
    "    fields,\n",
    "    dict_format,\n",
    "    time_col=\"time_period\",\n",
    "    primary_id=0,\n",
    "    figsize=(10, 5),\n",
    "    legend_loc='center left',\n",
    "    legend_bbox=(1.05, 0.5),  \n",
    "    ylabel=\"MT Emissions CO2e\",\n",
    "    xlabel=\"Time Period\",\n",
    "    title=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a stack plot of the selected fields for a given primary_id.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing output data.\n",
    "        fields (list): List of column names to plot.\n",
    "        dict_format (dict): Formatting dictionary for colors.\n",
    "        time_col (str): Name of the time column.\n",
    "        primary_id (int): Value of primary_id to filter.\n",
    "        figsize (tuple): Figure size.\n",
    "        legend_loc (str): Legend location.\n",
    "        legend_bbox (tuple): Legend bbox_to_anchor.\n",
    "        ylabel (str): Y-axis label.\n",
    "        xlabel (str): X-axis label.\n",
    "        title (str): Plot title.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    df_plot = df[df[ssp.key_primary].isin([primary_id])]\n",
    "\n",
    "    fig, ax = spu.plot_stack(\n",
    "        df_plot,\n",
    "        fields,\n",
    "        dict_formatting=dict_format,\n",
    "        field_x=time_col,\n",
    "        figtuple=(fig, ax),\n",
    "    )\n",
    "\n",
    "    ax.legend(loc=legend_loc, bbox_to_anchor=legend_bbox, title=\"Fields\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184008da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fields to plot and the formatting dictionary\n",
    "subsector_emission_fields = matt.get_all_subsector_emission_total_fields()\n",
    "\n",
    "dict_format = dict(\n",
    "    (k, {\"color\": v}) for (k, v) in\n",
    "    matt.get_subsector_color_map().items()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775ecbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_primary_ids = df_out.primary_id.unique()\n",
    "run_primary_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fe90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the emissions stack for the primary_id 0 (which is the baseline)\n",
    "\n",
    "for single_id in run_primary_ids:\n",
    "\n",
    "    plot_field_stack(\n",
    "        df_out,\n",
    "        subsector_emission_fields,\n",
    "        dict_format,\n",
    "        primary_id=single_id,\n",
    "        title=f\"Emissions Stack Plot Primary ID {single_id}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9782126f",
   "metadata": {},
   "source": [
    "# Export Wide File (Last Mandatory Step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9730299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_primaries = sorted(list(df_out[ssp.key_primary].unique()))\n",
    "\n",
    "# build if unable to simply read the data frame\n",
    "if df_in is None:\n",
    "    df_in = []\n",
    "     \n",
    "    for region in ssp.regions:\n",
    "        for primary in all_primaries: \n",
    "            df_in_filt = ssp.generate_scenario_database_from_primary_key(primary)\n",
    "            df_in.append(df_in_filt.get(region))\n",
    "    \n",
    "    df_in = pd.concat(df_in, axis = 0).reset_index(drop = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_export = pd.merge(\n",
    "    df_out,\n",
    "    df_in,\n",
    "    how = \"left\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# check output directory \n",
    "dir_pkg = os.path.join(\n",
    "    ssp.file_struct.dir_out, \n",
    "    f\"sisepuede_summary_results_run_{ssp.id_fs_safe}\"\n",
    ")\n",
    "os.makedirs(dir_pkg) if not os.path.exists(dir_pkg) else None\n",
    "\n",
    "\n",
    "for tab in [\"ATTRIBUTE_STRATEGY\"]:\n",
    "    table_df = ssp.database.db.read_table(tab)\n",
    "    if table_df is not None:\n",
    "        table_df.to_csv(\n",
    "            os.path.join(dir_pkg, f\"{tab}.csv\"),\n",
    "            index=None,\n",
    "            encoding=\"UTF-8\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Warning: Table {tab} returned None.\")\n",
    "\n",
    "\n",
    "df_primary = (\n",
    "    ssp\n",
    "    .odpt_primary\n",
    "    .get_indexing_dataframe(\n",
    "        sorted(list(df_out[ssp.key_primary].unique()))\n",
    "    )\n",
    ")\n",
    "    \n",
    "df_primary.to_csv(\n",
    "    os.path.join(dir_pkg, f\"ATTRIBUTE_PRIMARY.csv\"),\n",
    "    index = None,\n",
    "    encoding = \"UTF-8\"\n",
    ")\n",
    "\n",
    "df_export.to_csv(\n",
    "    os.path.join(dir_pkg, f\"sisepuede_results_{ssp.id_fs_safe}_WIDE_INPUTS_OUTPUTS.csv\"),\n",
    "    index = None,\n",
    "    encoding = \"UTF-8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b98596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the directory where the outputs are stored\n",
    "ssp.file_struct.dir_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db697933",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID_OUTPUT_DIR_PATH = os.path.join(\n",
    "    RUN_OUTPUT_DIR_PATH, \n",
    "    ssp.id_fs_safe\n",
    ")\n",
    "\n",
    "os.makedirs(RUN_ID_OUTPUT_DIR_PATH, exist_ok=True)\n",
    "\n",
    "df_primary.to_csv(\n",
    "    os.path.join(RUN_ID_OUTPUT_DIR_PATH, \"ATTRIBUTE_PRIMARY.csv\"),\n",
    "    index = None,\n",
    "    encoding = \"UTF-8\"\n",
    ")\n",
    "\n",
    "df_export.to_csv(\n",
    "\n",
    "    \n",
    "    os.path.join(RUN_ID_OUTPUT_DIR_PATH, f\"{ssp.id_fs_safe}.csv\"),\n",
    "    index = None,\n",
    "    encoding = \"UTF-8\"\n",
    ")\n",
    "\n",
    "for tab in [\"ATTRIBUTE_STRATEGY\"]:\n",
    "    table_df = ssp.database.db.read_table(tab)\n",
    "    if table_df is not None:\n",
    "        table_df.to_csv(\n",
    "            os.path.join(RUN_ID_OUTPUT_DIR_PATH, f\"{tab}.csv\"),\n",
    "            index=None,\n",
    "            encoding=\"UTF-8\"\n",
    "        )\n",
    "    else:\n",
    "        logger.warning(f\"Warning: Table {tab} returned None.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5efe8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954feb0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define fields  ---\n",
    "fields_str = (\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_mangroves_to_croplands:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_mangroves_to_forests_mangroves:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_mangroves_to_forests_primary:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_mangroves_to_forests_secondary:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_mangroves_to_grasslands:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_mangroves_to_other:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_mangroves_to_settlements:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_mangroves_to_wetlands:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_primary_to_croplands:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_primary_to_forests_mangroves:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_primary_to_forests_primary:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_primary_to_forests_secondary:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_primary_to_grasslands:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_primary_to_other:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_primary_to_settlements:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_primary_to_wetlands:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_secondary_to_croplands:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_secondary_to_forests_mangroves:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_secondary_to_forests_primary:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_secondary_to_forests_secondary:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_secondary_to_grasslands:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_secondary_to_other:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_secondary_to_settlements:\"\n",
    "   \"emission_co2e_co2_lndu_conversion_forests_secondary_to_wetlands:\"\n",
    "   \"emission_co2e_ch4_lndu_wetlands\"\n",
    ")\n",
    "subsector_emission_fields = fields_str.split(\":\")\n",
    "subsector_emission_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c7c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.filters.hp_filter import hpfilter\n",
    "\n",
    "def hpfilter_df(df, cols, by=\"primary_id\", x=\"time_period\", lamb=100):\n",
    "    df = df.sort_values([by, x]).copy()\n",
    "\n",
    "    def _apply_hp(g):\n",
    "        g = g.copy()\n",
    "        for col in cols:\n",
    "            cycle, trend = hpfilter(g[col], lamb=lamb)\n",
    "            g[col] = trend.clip(lower=0)  # keep only the trend, no negatives\n",
    "        return g\n",
    "\n",
    "    return df.groupby(by, group_keys=False).apply(_apply_hp)\n",
    "\n",
    "# Example: higher lambda → smoother trend\n",
    "df_hp = hpfilter_df(\n",
    "    df_out,\n",
    "    subsector_emission_fields,\n",
    "    by=\"primary_id\",\n",
    "    x=\"time_period\",\n",
    "    lamb=100  # try 100, 400, 1600 for different smoothness\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f677dcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the emissions stack for the primary_id 0 (which is the baseline)\n",
    "\n",
    "for single_id in run_primary_ids:\n",
    "\n",
    "    plot_field_stack(\n",
    "        df_out,\n",
    "        subsector_emission_fields,\n",
    "        dict_format,\n",
    "        primary_id=single_id,\n",
    "        title=f\"Emissions Stack Plot (HP filtered) {single_id}\" \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da6f923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the emissions stack for the primary_id 0 (which is the baseline)\n",
    "\n",
    "for single_id in run_primary_ids:\n",
    "\n",
    "    plot_field_stack(\n",
    "        df_hp,\n",
    "        subsector_emission_fields,\n",
    "        dict_format,\n",
    "        primary_id=single_id,\n",
    "        title=f\"Emissions Stack Plot (HP filtered) {single_id}\" \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f488cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out[subsector_emission_fields] = df_hp[subsector_emission_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80e673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define fields  ---\n",
    "fields_str = (\n",
    "   \"emission_co2e_co2_entc_generation_pp_biogas:\"\n",
    "   \"emission_co2e_co2_entc_generation_pp_biomass:\"\n",
    "   \"emission_co2e_co2_entc_generation_pp_coal:\"\n",
    "   \"emission_co2e_co2_entc_generation_pp_coal_ccs:\"\n",
    "   \"emission_co2e_co2_entc_generation_pp_gas:\"\n",
    "   \"emission_co2e_co2_entc_generation_pp_gas_ccs:\"\n",
    "   \"emission_co2e_co2_entc_generation_pp_geothermal:\"\n",
    "   \"emission_co2e_co2_entc_generation_pp_hydropower:\"\n",
    "   \"emission_co2e_co2_entc_generation_pp_nuclear:\"\n",
    "   \"emission_co2e_co2_entc_generation_pp_ocean:\"\n",
    "   \"emission_co2e_co2_entc_generation_pp_oil:\"\n",
    "   \"emission_co2e_co2_entc_generation_pp_solar:\"\n",
    "   \"emission_co2e_co2_entc_generation_pp_waste_incineration:\"\n",
    "   \"emission_co2e_co2_entc_generation_pp_wind:\"\n",
    "   \"emission_co2e_n2o_entc_generation_pp_biogas:\"\n",
    "   \"emission_co2e_n2o_entc_generation_pp_biomass:\"\n",
    "   \"emission_co2e_n2o_entc_generation_pp_coal:\"\n",
    "   \"emission_co2e_n2o_entc_generation_pp_coal_ccs:\"\n",
    "   \"emission_co2e_n2o_entc_generation_pp_gas:\"\n",
    "   \"emission_co2e_n2o_entc_generation_pp_gas_ccs:\"\n",
    "   \"emission_co2e_n2o_entc_generation_pp_geothermal:\"\n",
    "   \"emission_co2e_n2o_entc_generation_pp_hydropower:\"\n",
    "   \"emission_co2e_n2o_entc_generation_pp_nuclear:\"\n",
    "   \"emission_co2e_n2o_entc_generation_pp_ocean:\"\n",
    "   \"emission_co2e_n2o_entc_generation_pp_oil:\"\n",
    "   \"emission_co2e_n2o_entc_generation_pp_solar:\"\n",
    "   \"emission_co2e_n2o_entc_generation_pp_waste_incineration:\"\n",
    "   \"emission_co2e_n2o_entc_generation_pp_wind:\"\n",
    "   \"emission_co2e_ch4_entc_generation_pp_biogas:\"\n",
    "   \"emission_co2e_ch4_entc_generation_pp_biomass:\"\n",
    "   \"emission_co2e_ch4_entc_generation_pp_coal:\"\n",
    "   \"emission_co2e_ch4_entc_generation_pp_coal_ccs:\"\n",
    "   \"emission_co2e_ch4_entc_generation_pp_gas:\"\n",
    "   \"emission_co2e_ch4_entc_generation_pp_gas_ccs:\"\n",
    "   \"emission_co2e_ch4_entc_generation_pp_geothermal:\"\n",
    "   \"emission_co2e_ch4_entc_generation_pp_hydropower:\"\n",
    "   \"emission_co2e_ch4_entc_generation_pp_nuclear:\"\n",
    "   \"emission_co2e_ch4_entc_generation_pp_ocean:\"\n",
    "   \"emission_co2e_ch4_entc_generation_pp_oil:\"\n",
    "   \"emission_co2e_ch4_entc_generation_pp_solar:\"\n",
    "   \"emission_co2e_ch4_entc_generation_pp_waste_incineration:\"\n",
    "   \"emission_co2e_ch4_entc_generation_pp_wind\"\n",
    ")\n",
    "subsector_emission_fields = fields_str.split(\":\")\n",
    "subsector_emission_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3988af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the emissions stack for the primary_id 0 (which is the baseline)\n",
    "for single_id in run_primary_ids:\n",
    "\n",
    "    plot_field_stack(\n",
    "        df_hp,\n",
    "        subsector_emission_fields,\n",
    "        dict_format,\n",
    "        primary_id=single_id,\n",
    "        title=f\"Emissions Stack Plot (HP filtered) {single_id}\" \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cut year where you want the flat projection to start\n",
    "cut_year = 2\n",
    "\n",
    "for pid in run_primary_ids:\n",
    "    print(pid)\n",
    "    # Mask for the future part\n",
    "    mask_future = (df_out[\"primary_id\"] == pid) & (df_out[\"time_period\"] >= cut_year)\n",
    "\n",
    "    # Get the last historical values before the cut\n",
    "    last_vals = df_out.loc[\n",
    "        (df_out[\"primary_id\"] == pid) & (df_out[\"time_period\"] < cut_year),\n",
    "        subsector_emission_fields\n",
    "    ].iloc[-1]\n",
    "\n",
    "    # Assign the last values to all future rows\n",
    "    df_out.loc[mask_future, subsector_emission_fields] = last_vals.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e473c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the emissions stack for the primary_id 0 (which is the baseline)\n",
    "for single_id in run_primary_ids:\n",
    "\n",
    "    plot_field_stack(\n",
    "        df_out,\n",
    "        subsector_emission_fields,\n",
    "        dict_format,\n",
    "        primary_id=single_id,\n",
    "        title=f\"Emissions Stack Plot {single_id}\" \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ca9ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define fields  ---\n",
    "fields_str = (\n",
    "    \"emission_co2e_co2_fgtv_fuel_coal:\"\n",
    "    \"emission_co2e_co2_fgtv_fuel_natural_gas:\"\n",
    "    \"emission_co2e_co2_fgtv_fuel_oil:\"\n",
    "    \"emission_co2e_co2_entc_fuel_mining_and_extraction_me_coal:\"\n",
    "    \"emission_co2e_co2_entc_fuel_mining_and_extraction_me_crude:\"\n",
    "    \"emission_co2e_co2_entc_fuel_mining_and_extraction_me_natural_gas:\"\n",
    "    \"emission_co2e_co2_entc_processing_and_refinement_fp_ammonia_production:\"\n",
    "    \"emission_co2e_co2_entc_processing_and_refinement_fp_hydrogen_electrolysis:\"\n",
    "    \"emission_co2e_co2_entc_processing_and_refinement_fp_hydrogen_gasification:\"\n",
    "    \"emission_co2e_co2_entc_processing_and_refinement_fp_hydrogen_reformation:\"\n",
    "    \"emission_co2e_co2_entc_processing_and_refinement_fp_hydrogen_reformation_ccs:\"\n",
    "    \"emission_co2e_co2_entc_processing_and_refinement_fp_natural_gas:\"\n",
    "    \"emission_co2e_co2_entc_processing_and_refinement_fp_petroleum_refinement:\"\n",
    "    \"emission_co2e_ch4_fgtv_fuel_coal:\"\n",
    "    \"emission_co2e_ch4_fgtv_fuel_natural_gas:\"\n",
    "    \"emission_co2e_ch4_fgtv_fuel_oil:\"\n",
    "    \"emission_co2e_ch4_entc_fuel_mining_and_extraction_me_coal:\"\n",
    "    \"emission_co2e_ch4_entc_fuel_mining_and_extraction_me_crude:\"\n",
    "    \"emission_co2e_ch4_entc_fuel_mining_and_extraction_me_natural_gas:\"\n",
    "    \"emission_co2e_ch4_entc_processing_and_refinement_fp_ammonia_production:\"\n",
    "    \"emission_co2e_ch4_entc_processing_and_refinement_fp_hydrogen_electrolysis:\"\n",
    "    \"emission_co2e_ch4_entc_processing_and_refinement_fp_hydrogen_gasification:\"\n",
    "    \"emission_co2e_ch4_entc_processing_and_refinement_fp_hydrogen_reformation:\"\n",
    "    \"emission_co2e_ch4_entc_processing_and_refinement_fp_hydrogen_reformation_ccs:\"\n",
    "    \"emission_co2e_ch4_entc_processing_and_refinement_fp_natural_gas:\"\n",
    "    \"emission_co2e_ch4_entc_processing_and_refinement_fp_petroleum_refinement:\"\n",
    "    \"emission_co2e_n2o_fgtv_fuel_coal:\"\n",
    "    \"emission_co2e_n2o_fgtv_fuel_natural_gas:\"\n",
    "    \"emission_co2e_n2o_fgtv_fuel_oil:\"\n",
    "    \"emission_co2e_n2o_entc_fuel_mining_and_extraction_me_coal:\"\n",
    "    \"emission_co2e_n2o_entc_fuel_mining_and_extraction_me_crude:\"\n",
    "    \"emission_co2e_n2o_entc_fuel_mining_and_extraction_me_natural_gas:\"\n",
    "    \"emission_co2e_n2o_entc_processing_and_refinement_fp_ammonia_production:\"\n",
    "    \"emission_co2e_n2o_entc_processing_and_refinement_fp_hydrogen_electrolysis:\"\n",
    "    \"emission_co2e_n2o_entc_processing_and_refinement_fp_hydrogen_gasification:\"\n",
    "    \"emission_co2e_n2o_entc_processing_and_refinement_fp_hydrogen_reformation:\"\n",
    "    \"emission_co2e_n2o_entc_processing_and_refinement_fp_hydrogen_reformation_ccs:\"\n",
    "    \"emission_co2e_n2o_entc_processing_and_refinement_fp_natural_gas:\"\n",
    "    \"emission_co2e_n2o_entc_processing_and_refinement_fp_petroleum_refinement\"\n",
    ")\n",
    "subsector_emission_fields = fields_str.split(\":\")\n",
    "subsector_emission_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0091729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.filters.hp_filter import hpfilter\n",
    "\n",
    "def hpfilter_df(df, cols, by=\"primary_id\", x=\"time_period\", lamb=100):\n",
    "    df = df.sort_values([by, x]).copy()\n",
    "\n",
    "    def _apply_hp(g):\n",
    "        g = g.copy()\n",
    "        for col in cols:\n",
    "            cycle, trend = hpfilter(g[col], lamb=lamb)\n",
    "            g[col] = trend.clip(lower=0)  # keep only the trend, no negatives\n",
    "        return g\n",
    "\n",
    "    return df.groupby(by, group_keys=False).apply(_apply_hp)\n",
    "\n",
    "# Example: higher lambda → smoother trend\n",
    "df_hp = hpfilter_df(\n",
    "    df_out,\n",
    "    subsector_emission_fields,\n",
    "    by=\"primary_id\",\n",
    "    x=\"time_period\",\n",
    "    lamb=100  # try 100, 400, 1600 for different smoothness\n",
    ")\n",
    "\n",
    "plot_field_stack(\n",
    "    df_hp,\n",
    "    subsector_emission_fields,\n",
    "    dict_format,\n",
    "    primary_id=0,\n",
    "    title=\"Emissions Stack Plot (HP filtered)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa50b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cut year where you want the flat projection to start\n",
    "cut_year = 2\n",
    "\n",
    "for pid in run_primary_ids:\n",
    "    print(pid)\n",
    "    # Mask for the future part\n",
    "    mask_future = (df_out[\"primary_id\"] == pid) & (df_out[\"time_period\"] >= cut_year)\n",
    "\n",
    "    # Get the last historical values before the cut\n",
    "    last_vals = df_out.loc[\n",
    "        (df_out[\"primary_id\"] == pid) & (df_out[\"time_period\"] < cut_year),\n",
    "        subsector_emission_fields\n",
    "    ].iloc[-1]\n",
    "\n",
    "    # Assign the last values to all future rows\n",
    "    df_out.loc[mask_future, subsector_emission_fields] = last_vals.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ecc4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the emissions stack for the primary_id 0 (which is the baseline)\n",
    "for single_id in run_primary_ids:\n",
    "\n",
    "    plot_field_stack(\n",
    "        df_out,\n",
    "        subsector_emission_fields,\n",
    "        dict_format,\n",
    "        primary_id=single_id,\n",
    "        title=f\"Emissions Stack Plot {single_id}\" \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4c2276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define fields  ---\n",
    "fields_str = (\n",
    "   \"emission_co2e_co2_scoe_commercial_municipal:emission_co2e_co2_scoe_other_se:emission_co2e_co2_scoe_residential:\"\n",
    "   \"emission_co2e_ch4_scoe_commercial_municipal:emission_co2e_ch4_scoe_other_se:emission_co2e_ch4_scoe_residential:\"\n",
    "   \"emission_co2e_n2o_scoe_commercial_municipal:emission_co2e_n2o_scoe_other_se:emission_co2e_n2o_scoe_residential\"\n",
    "\n",
    ")\n",
    "subsector_emission_fields = fields_str.split(\":\")\n",
    "subsector_emission_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3066a52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the emissions stack for the primary_id 0 (which is the baseline)\n",
    "for single_id in run_primary_ids:\n",
    "\n",
    "    plot_field_stack(\n",
    "        df_out,\n",
    "        subsector_emission_fields,\n",
    "        dict_format,\n",
    "        primary_id=single_id,\n",
    "        title=f\"Emissions Stack Plot {single_id}\" \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94530ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cut year where you want the flat projection to start\n",
    "cut_year = 3\n",
    "pid = run_primary_ids[0]\n",
    "print(run_primary_ids[0])\n",
    "# Mask for the future part\n",
    "mask_future = (df_out[\"primary_id\"] == pid) & (df_out[\"time_period\"] >= cut_year)\n",
    "\n",
    "# Get the last historical values before the cut\n",
    "last_vals = df_out.loc[\n",
    "    (df_out[\"primary_id\"] == pid) & (df_out[\"time_period\"] < cut_year),\n",
    "    subsector_emission_fields\n",
    "].iloc[-1]\n",
    "\n",
    "# Assign the last values to all future rows\n",
    "df_out.loc[mask_future, subsector_emission_fields] = last_vals.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0afd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cut year where you want the flat projection to start\n",
    "cut_year = 3\n",
    "pid = run_primary_ids[4]\n",
    "print(run_primary_ids[4])\n",
    "# Mask for the future part\n",
    "mask_future = (df_out[\"primary_id\"] == pid) & (df_out[\"time_period\"] >= cut_year)\n",
    "\n",
    "# Get the last historical values before the cut\n",
    "last_vals = df_out.loc[\n",
    "    (df_out[\"primary_id\"] == pid) & (df_out[\"time_period\"] < cut_year),\n",
    "    subsector_emission_fields\n",
    "].iloc[-1]\n",
    "\n",
    "# Assign the last values to all future rows\n",
    "df_out.loc[mask_future, subsector_emission_fields] = last_vals.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b697eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: higher lambda → smoother trend\n",
    "df_hp = hpfilter_df(\n",
    "    df_out,\n",
    "    subsector_emission_fields,\n",
    "    by=\"primary_id\",\n",
    "    x=\"time_period\",\n",
    "    lamb=1600  # try 100, 400, 1600 for different smoothness\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31291c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the emissions stack for the primary_id 0 (which is the baseline)\n",
    "\n",
    "for single_id in run_primary_ids:\n",
    "\n",
    "    plot_field_stack(\n",
    "        df_hp,\n",
    "        subsector_emission_fields,\n",
    "        dict_format,\n",
    "        primary_id=single_id,\n",
    "        title=f\"Emissions Stack Plot (HP filtered) {single_id}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f312a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out[subsector_emission_fields] = df_hp[subsector_emission_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13048d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssp_uganda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
